
---
title: "05. Sparklyr write to Delta"
output:
  html_document:
    toc: true
---


```{r}
 options(repos = c(CRAN = "https://packagemanager.posit.co/cran/__linux__/focal/latest"))
 options()$repos
  
 r_lib_path <- "/dbfs/R/library"
 .libPaths(c(r_lib_path, .libPaths()))

pacman::p_load(
  sparklyr, 
  arrow,
  dplyr
)

```


```{fs}
ls /
```

```{r}
suppressWarnings(sc <- spark_connect(method = "databricks"))

#patient_admits <- spark_read_parquet(sc, "file:/dbfs/Data/CoreCDM/Silver/patient-admits/part-0.parquet")

patients <- spark_read_csv(sc, "file:/dbfs/Data/mimic-iv-demo/2.2/hosp/patients.csv.gz")
admissions <- spark_read_csv(sc, "file:/dbfs/Data/mimic-iv-demo/2.2/hosp/admissions.csv.gz")
labevents <- spark_read_csv(sc, "file:/dbfs/Data/mimic-iv-demo/2.2/hosp/labevents.csv.gz")
d_labitems <- spark_read_csv(sc, "file:/dbfs/Data/mimic-iv-demo/2.2/hosp/d_labitems.csv.gz")


```


```{r}
patients |>
head() |> 
display()

```


```{r}
#DBI::dbSendQuery(sc, "CREATE SCHEMA IF NOT EXISTS mimic_iv_demo;")

spark_write_table(admissions, "mimic_iv_demo.hosp_admissions", mode = "overwrite")
spark_write_table(patients, "mimic_iv_demo.hosp_patients", mode = "overwrite")
spark_write_table(labevents, "mimic_iv_demo.hosp_labevents", mode = "overwrite")
spark_write_table(labevents, "mimic_iv_demo.hosp_d_labitems", mode = "overwrite")

```


```{r}
%sql

select * from hive_metastore.mimic_iv_demo.hosp_${df_name}

```


```{r}
patients |>
spark_write_delta("file:/dbfs/Data/mimic-iv-demo/hosp/patients", 
options = c())
```


```{r}
admission_type_counts <- 
patient_admits |> 
group_by(admission_type) |>
count(sort = TRUE)

display(admission_type_counts)
```


```{r}
admission_type_counts |>
spark_write_delta("file:/dbfs/Data/CoreCDM/Gold/admission_type_counts", 
options = c())

```


```{r}

```
